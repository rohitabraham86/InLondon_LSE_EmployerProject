{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95dc4bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries.\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "### Download data from TFL website: https://cycling.data.tfl.gov.uk/\n",
    "## This notebook will concat TFL files and revert files after Sept 2022 to the previous format.\n",
    "\n",
    "# Load one of the weekly Santander 2022 dataset files.\n",
    "data = pd.read_csv('300JourneyDataExtract12Jan2022-18Jan2022.csv')\n",
    "\n",
    "# Explore the DataFrame.\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eccee82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the DataFrame.\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95b4cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing one file from the 2023 dataset.\n",
    "data2 = pd.read_csv('352JourneyDataExtract09Jan2023-15Jan2023.csv')\n",
    "\n",
    "# Explore the data.\n",
    "data2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a89165",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the DataFrame.\n",
    "data2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c32500",
   "metadata": {},
   "source": [
    "### TFL have changed the data collection method, there are different columns from September 2022."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aea6ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download files from TFL website: https://cycling.data.tfl.gov.uk/\n",
    "# Create a dataframe from all weekly files that use new set of columns. \n",
    "path = r'C:\\Users\\Tamas\\Python\\Untitled Folder\\LSE_DA_Employer_Project_TW_London\\London_Santander\\Newdata' # use your path\n",
    "all_files = glob.glob(os.path.join(path, \"*.csv\")) # advisable to use os.path.join as this makes concatenation OS independent\n",
    "\n",
    "df_from_each_file = (pd.read_csv(f) for f in all_files)\n",
    "concatenated_df   = pd.concat(df_from_each_file, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a478cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the data.\n",
    "data2 = concatenated_df\n",
    "data2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb4ebda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change DataFrame to use the data as in the earlier versions.\n",
    "data2.rename(columns = {'Bike number':'Bike Id','Number':'Rental Id'}, inplace=True)\n",
    "data2['Duration'] = data2['Total duration (ms)'].apply(lambda x: x/1000)\n",
    "data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c3c027",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unused columns. \n",
    "data2=data2.drop(['Total duration','Total duration (ms)'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ed878a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust column names to match earlier format.\n",
    "data2.rename(columns = {'End date':'End Date',\n",
    "                        'Start date':'Start Date',\n",
    "                        'Start station number':'StartStation Id',\n",
    "                        'Start station':'StartStation Name',\n",
    "                        'End station number':'EndStation Id',\n",
    "                        'End station':'EndStation Name'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de18b9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check columns and data types.\n",
    "data2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06027832",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Concat with other data, add more weekly files if needed.\n",
    "# df = pd.concat([data, data2], ignore_index=True)\n",
    "# df.info()\n",
    "# Otherwise just rename the DataFrame to continue.\n",
    "df = data2\n",
    "df.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0efdbddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the DataFrame.\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94de50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the date columns to the correct format.\n",
    "df['Start Date'] = pd.to_datetime(df['Start Date'])\n",
    "df['End Date'] = pd.to_datetime(df['End Date'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2383ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame as a CSV file.\n",
    "df.to_csv('bikehire_concat.csv', encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
